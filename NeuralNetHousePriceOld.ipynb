{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1000 non-null   int64  \n",
      " 1   MSSubClass     1000 non-null   int64  \n",
      " 2   MSZoning       1000 non-null   object \n",
      " 3   LotFrontage    827 non-null    float64\n",
      " 4   LotArea        1000 non-null   int64  \n",
      " 5   Street         1000 non-null   object \n",
      " 6   Alley          65 non-null     object \n",
      " 7   LotShape       1000 non-null   object \n",
      " 8   LandContour    1000 non-null   object \n",
      " 9   Utilities      1000 non-null   object \n",
      " 10  LotConfig      1000 non-null   object \n",
      " 11  LandSlope      1000 non-null   object \n",
      " 12  Neighborhood   1000 non-null   object \n",
      " 13  Condition1     1000 non-null   object \n",
      " 14  Condition2     1000 non-null   object \n",
      " 15  BldgType       1000 non-null   object \n",
      " 16  HouseStyle     1000 non-null   object \n",
      " 17  OverallQual    1000 non-null   int64  \n",
      " 18  OverallCond    1000 non-null   int64  \n",
      " 19  YearBuilt      1000 non-null   int64  \n",
      " 20  YearRemodAdd   1000 non-null   int64  \n",
      " 21  RoofStyle      1000 non-null   object \n",
      " 22  RoofMatl       1000 non-null   object \n",
      " 23  Exterior1st    1000 non-null   object \n",
      " 24  Exterior2nd    1000 non-null   object \n",
      " 25  MasVnrType     410 non-null    object \n",
      " 26  MasVnrArea     994 non-null    float64\n",
      " 27  ExterQual      1000 non-null   object \n",
      " 28  ExterCond      1000 non-null   object \n",
      " 29  Foundation     1000 non-null   object \n",
      " 30  BsmtQual       976 non-null    object \n",
      " 31  BsmtCond       976 non-null    object \n",
      " 32  BsmtExposure   975 non-null    object \n",
      " 33  BsmtFinType1   976 non-null    object \n",
      " 34  BsmtFinSF1     1000 non-null   int64  \n",
      " 35  BsmtFinType2   975 non-null    object \n",
      " 36  BsmtFinSF2     1000 non-null   int64  \n",
      " 37  BsmtUnfSF      1000 non-null   int64  \n",
      " 38  TotalBsmtSF    1000 non-null   int64  \n",
      " 39  Heating        1000 non-null   object \n",
      " 40  HeatingQC      1000 non-null   object \n",
      " 41  CentralAir     1000 non-null   object \n",
      " 42  Electrical     1000 non-null   object \n",
      " 43  1stFlrSF       1000 non-null   int64  \n",
      " 44  2ndFlrSF       1000 non-null   int64  \n",
      " 45  LowQualFinSF   1000 non-null   int64  \n",
      " 46  GrLivArea      1000 non-null   int64  \n",
      " 47  BsmtFullBath   1000 non-null   int64  \n",
      " 48  BsmtHalfBath   1000 non-null   int64  \n",
      " 49  FullBath       1000 non-null   int64  \n",
      " 50  HalfBath       1000 non-null   int64  \n",
      " 51  BedroomAbvGr   1000 non-null   int64  \n",
      " 52  KitchenAbvGr   1000 non-null   int64  \n",
      " 53  KitchenQual    1000 non-null   object \n",
      " 54  TotRmsAbvGrd   1000 non-null   int64  \n",
      " 55  Functional     1000 non-null   object \n",
      " 56  Fireplaces     1000 non-null   int64  \n",
      " 57  FireplaceQu    522 non-null    object \n",
      " 58  GarageType     944 non-null    object \n",
      " 59  GarageYrBlt    944 non-null    float64\n",
      " 60  GarageFinish   944 non-null    object \n",
      " 61  GarageCars     1000 non-null   int64  \n",
      " 62  GarageArea     1000 non-null   int64  \n",
      " 63  GarageQual     944 non-null    object \n",
      " 64  GarageCond     944 non-null    object \n",
      " 65  PavedDrive     1000 non-null   object \n",
      " 66  WoodDeckSF     1000 non-null   int64  \n",
      " 67  OpenPorchSF    1000 non-null   int64  \n",
      " 68  EnclosedPorch  1000 non-null   int64  \n",
      " 69  3SsnPorch      1000 non-null   int64  \n",
      " 70  ScreenPorch    1000 non-null   int64  \n",
      " 71  PoolArea       1000 non-null   int64  \n",
      " 72  PoolQC         2 non-null      object \n",
      " 73  Fence          194 non-null    object \n",
      " 74  MiscFeature    43 non-null     object \n",
      " 75  MiscVal        1000 non-null   int64  \n",
      " 76  MoSold         1000 non-null   int64  \n",
      " 77  YrSold         1000 non-null   int64  \n",
      " 78  SaleType       1000 non-null   object \n",
      " 79  SaleCondition  1000 non-null   object \n",
      " 80  SalePrice      1000 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 632.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1. Load the dataset\n",
    "# -----------------------------\n",
    "# Replace 'house_prices.csv' with the path to your dataset.\n",
    "data = pd.read_csv('train.csv')\n",
    "data\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
      "       ...\n",
      "       'SaleType_ConLI', 'SaleType_ConLw', 'SaleType_New', 'SaleType_Oth',\n",
      "       'SaleType_WD', 'SaleCondition_AdjLand', 'SaleCondition_Alloca',\n",
      "       'SaleCondition_Family', 'SaleCondition_Normal',\n",
      "       'SaleCondition_Partial'],\n",
      "      dtype='object', length=229)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 2. Data Cleaning\n",
    "# -----------------------------\n",
    "\n",
    "target='SalePrice' # Define the target column\n",
    "\n",
    "# Identify categorical columns (if they are not already type 'category')\n",
    "categorical_cols = data.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# One-hot encode these columns (original columns are dropped automatically)\n",
    "data = pd.get_dummies(data, columns=categorical_cols, dtype=int,drop_first=True)\n",
    "\n",
    "clean_numeric_cols = [col for col in data if data[col].isna().sum() == 0]\n",
    "data_clean = data[clean_numeric_cols]\n",
    "print(data_clean.columns)\n",
    "\n",
    "# Ensure that the target column 'price' is present.\n",
    "if 'SalePrice' not in data_clean.columns:\n",
    "    raise ValueError(\"The target column 'price' is not present in the complete numeric data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected top N features: ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'ExterQual_TA', 'TotRmsAbvGrd', 'FullBath', 'KitchenQual_TA', 'YearBuilt', 'YearRemodAdd', 'Foundation_PConc', 'Fireplaces', 'BsmtQual_TA']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 3. Feature Selection\n",
    "# -----------------------------\n",
    "# Compute the correlation matrix using only the cleaned numeric data.\n",
    "corr_matrix = data_clean.corr()\n",
    "\n",
    "# Compute absolute correlations of features with the target and drop the target itself.\n",
    "target_corr = corr_matrix['SalePrice'].drop('SalePrice').abs().sort_values(ascending=False)\n",
    "\n",
    "# Select only the top 4 features with the highest correlation with 'SalesPrice'\n",
    "topN_features = target_corr.head(15).index\n",
    "print(\"Selected top N features:\", list(topN_features))\n",
    "\n",
    "# Save the feature column names for reindexing later.\n",
    "train_columns = data_clean.drop(columns=[target]).columns\n",
    "\n",
    "# Define input features (X) and target variable (y).\n",
    "X = data_clean[topN_features].values\n",
    "y = data_clean['SalePrice'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4. Data Preprocessing\n",
    "# -----------------------------\n",
    "# Split the data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features to improve training stability.\n",
    "scalerX = StandardScaler()\n",
    "X_train = scalerX.fit_transform(X_train)\n",
    "X_test = scalerX.transform(X_test)\n",
    "\n",
    "scalerY = StandardScaler()\n",
    "y_train = scalerY.fit_transform(y_train)\n",
    "y_test = scalerY.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy arrays to PyTorch tensors.\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create a TensorDataset and DataLoader for batch processing.\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5. Define the Neural Network Model\n",
    "# -----------------------------\n",
    "class HousePriceModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(HousePriceModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)  # Output layer for regression\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HousePriceModel(input_dim=X_train.shape[1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 0.1408\n",
      "Epoch [20/1000], Loss: 0.1178\n",
      "Epoch [30/1000], Loss: 0.1021\n",
      "Epoch [40/1000], Loss: 0.0919\n",
      "Epoch [50/1000], Loss: 0.0813\n",
      "Epoch [60/1000], Loss: 0.0757\n",
      "Epoch [70/1000], Loss: 0.0648\n",
      "Epoch [80/1000], Loss: 0.0561\n",
      "Epoch [90/1000], Loss: 0.0548\n",
      "Epoch [100/1000], Loss: 0.0521\n",
      "Epoch [110/1000], Loss: 0.0369\n",
      "Epoch [120/1000], Loss: 0.0350\n",
      "Epoch [130/1000], Loss: 0.0330\n",
      "Epoch [140/1000], Loss: 0.0290\n",
      "Epoch [150/1000], Loss: 0.0275\n",
      "Epoch [160/1000], Loss: 0.0257\n",
      "Epoch [170/1000], Loss: 0.0267\n",
      "Epoch [180/1000], Loss: 0.0239\n",
      "Epoch [190/1000], Loss: 0.0220\n",
      "Epoch [200/1000], Loss: 0.0230\n",
      "Epoch [210/1000], Loss: 0.0196\n",
      "Epoch [220/1000], Loss: 0.0190\n",
      "Epoch [230/1000], Loss: 0.0193\n",
      "Epoch [240/1000], Loss: 0.0221\n",
      "Epoch [250/1000], Loss: 0.0160\n",
      "Epoch [260/1000], Loss: 0.0151\n",
      "Epoch [270/1000], Loss: 0.0166\n",
      "Epoch [280/1000], Loss: 0.0157\n",
      "Epoch [290/1000], Loss: 0.0156\n",
      "Epoch [300/1000], Loss: 0.0137\n",
      "Epoch [310/1000], Loss: 0.0139\n",
      "Epoch [320/1000], Loss: 0.0151\n",
      "Epoch [330/1000], Loss: 0.0163\n",
      "Epoch [340/1000], Loss: 0.0158\n",
      "Epoch [350/1000], Loss: 0.0113\n",
      "Epoch [360/1000], Loss: 0.0123\n",
      "Epoch [370/1000], Loss: 0.0122\n",
      "Epoch [380/1000], Loss: 0.0103\n",
      "Epoch [390/1000], Loss: 0.0125\n",
      "Epoch [400/1000], Loss: 0.0097\n",
      "Epoch [410/1000], Loss: 0.0105\n",
      "Epoch [420/1000], Loss: 0.0130\n",
      "Epoch [430/1000], Loss: 0.0089\n",
      "Epoch [440/1000], Loss: 0.0127\n",
      "Epoch [450/1000], Loss: 0.0090\n",
      "Epoch [460/1000], Loss: 0.0106\n",
      "Epoch [470/1000], Loss: 0.0083\n",
      "Epoch [480/1000], Loss: 0.0084\n",
      "Epoch [490/1000], Loss: 0.0085\n",
      "Epoch [500/1000], Loss: 0.0099\n",
      "Epoch [510/1000], Loss: 0.0086\n",
      "Epoch [520/1000], Loss: 0.0078\n",
      "Epoch [530/1000], Loss: 0.0065\n",
      "Epoch [540/1000], Loss: 0.0068\n",
      "Epoch [550/1000], Loss: 0.0069\n",
      "Epoch [560/1000], Loss: 0.0083\n",
      "Epoch [570/1000], Loss: 0.0058\n",
      "Epoch [580/1000], Loss: 0.0086\n",
      "Epoch [590/1000], Loss: 0.0067\n",
      "Epoch [600/1000], Loss: 0.0072\n",
      "Epoch [610/1000], Loss: 0.0072\n",
      "Epoch [620/1000], Loss: 0.0056\n",
      "Epoch [630/1000], Loss: 0.0061\n",
      "Epoch [640/1000], Loss: 0.0052\n",
      "Epoch [650/1000], Loss: 0.0060\n",
      "Epoch [660/1000], Loss: 0.0057\n",
      "Epoch [670/1000], Loss: 0.0049\n",
      "Epoch [680/1000], Loss: 0.0126\n",
      "Epoch [690/1000], Loss: 0.0052\n",
      "Epoch [700/1000], Loss: 0.0046\n",
      "Epoch [710/1000], Loss: 0.0063\n",
      "Epoch [720/1000], Loss: 0.0046\n",
      "Epoch [730/1000], Loss: 0.0044\n",
      "Epoch [740/1000], Loss: 0.0063\n",
      "Epoch [750/1000], Loss: 0.0039\n",
      "Epoch [760/1000], Loss: 0.0036\n",
      "Epoch [770/1000], Loss: 0.0060\n",
      "Epoch [780/1000], Loss: 0.0044\n",
      "Epoch [790/1000], Loss: 0.0046\n",
      "Epoch [800/1000], Loss: 0.0068\n",
      "Epoch [810/1000], Loss: 0.0043\n",
      "Epoch [820/1000], Loss: 0.0039\n",
      "Epoch [830/1000], Loss: 0.0037\n",
      "Epoch [840/1000], Loss: 0.0049\n",
      "Epoch [850/1000], Loss: 0.0033\n",
      "Epoch [860/1000], Loss: 0.0044\n",
      "Epoch [870/1000], Loss: 0.0043\n",
      "Epoch [880/1000], Loss: 0.0038\n",
      "Epoch [890/1000], Loss: 0.0070\n",
      "Epoch [900/1000], Loss: 0.0039\n",
      "Epoch [910/1000], Loss: 0.0028\n",
      "Epoch [920/1000], Loss: 0.0037\n",
      "Epoch [930/1000], Loss: 0.0031\n",
      "Epoch [940/1000], Loss: 0.0127\n",
      "Epoch [950/1000], Loss: 0.0035\n",
      "Epoch [960/1000], Loss: 0.0026\n",
      "Epoch [970/1000], Loss: 0.0060\n",
      "Epoch [980/1000], Loss: 0.0033\n",
      "Epoch [990/1000], Loss: 0.0031\n",
      "Epoch [1000/1000], Loss: 0.0029\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6. Set Up Loss Function and Optimizer\n",
    "# -----------------------------\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Train the Model\n",
    "# -----------------------------\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Squared Error: 0.23265963792800903\n",
      "Test MSE (scikit-learn): 1623653543.4024796\n",
      "Test R2: 0.6112133934868966\n"
     ]
    }
   ],
   "source": [
    "# 8. Evaluate the Model\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor.to(device))\n",
    "    test_loss = criterion(predictions, y_test_tensor.to(device)).item()\n",
    "    print(\"Test Mean Squared Error:\", test_loss)\n",
    "\n",
    "\n",
    "# Optionally, to evaluate using scikit-learn's MSE:\n",
    "predictions_np = predictions.cpu().numpy()\n",
    "predictions_np = scalerY.inverse_transform(predictions_np)\n",
    "y_test=y_test_tensor.cpu().numpy()\n",
    "y_test = scalerY.inverse_transform(y_test_tensor)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions_np)\n",
    "r2=r2_score(y_test, predictions_np)\n",
    "print(\"Test MSE (scikit-learn):\", mse)\n",
    "print(\"Test R2:\", r2)\n",
    "#Test Mean Squared Error: 935741376.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission Preview:\n",
      "     ID      SALEPRICE\n",
      "0  1001  107163.757812\n",
      "1  1002   58597.085938\n",
      "2  1003  247260.796875\n",
      "3  1004  180346.078125\n",
      "4  1005  212003.453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the test.csv file (which lacks SalePrice but includes an 'Id' column)\n",
    "test_df = pd.read_csv('test.csv')\n",
    "ids = test_df['Id']\n",
    "\n",
    "# One-hot encode the test data using the same categorical columns as before\n",
    "test_encoded = pd.get_dummies(test_df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Reindex to match the training features\n",
    "test_encoded = test_encoded.reindex(columns=train_columns, fill_value=0)\n",
    "test_encoded = test_encoded[topN_features]  # Select the same top features\n",
    "test_encoded = test_encoded.astype(float)\n",
    "X_test_new = scalerX.transform(test_encoded)\n",
    "\n",
    "X_test_tensor_new = torch.tensor(X_test_new, dtype=torch.float32)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test_tensor_new.to(device))\n",
    "    test_predictions_np = test_predictions.cpu().numpy()\n",
    "\n",
    "# Inverse transform predictions to get SalePrice in the original scale.\n",
    "test_predictions_unscaled = scalerY.inverse_transform(test_predictions_np)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': ids.astype(int),\n",
    "    'SALEPRICE': test_predictions_unscaled.flatten().astype(float)\n",
    "})\n",
    "\n",
    "\n",
    "print(\"\\nSubmission Preview:\")\n",
    "print(submission_df.head())\n",
    "\n",
    "# Optionally, export to CSV:\n",
    "submission_df.to_csv('predictions2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

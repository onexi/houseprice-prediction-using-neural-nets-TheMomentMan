{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1000 non-null   int64  \n",
      " 1   MSSubClass     1000 non-null   int64  \n",
      " 2   MSZoning       1000 non-null   object \n",
      " 3   LotFrontage    827 non-null    float64\n",
      " 4   LotArea        1000 non-null   int64  \n",
      " 5   Street         1000 non-null   object \n",
      " 6   Alley          65 non-null     object \n",
      " 7   LotShape       1000 non-null   object \n",
      " 8   LandContour    1000 non-null   object \n",
      " 9   Utilities      1000 non-null   object \n",
      " 10  LotConfig      1000 non-null   object \n",
      " 11  LandSlope      1000 non-null   object \n",
      " 12  Neighborhood   1000 non-null   object \n",
      " 13  Condition1     1000 non-null   object \n",
      " 14  Condition2     1000 non-null   object \n",
      " 15  BldgType       1000 non-null   object \n",
      " 16  HouseStyle     1000 non-null   object \n",
      " 17  OverallQual    1000 non-null   int64  \n",
      " 18  OverallCond    1000 non-null   int64  \n",
      " 19  YearBuilt      1000 non-null   int64  \n",
      " 20  YearRemodAdd   1000 non-null   int64  \n",
      " 21  RoofStyle      1000 non-null   object \n",
      " 22  RoofMatl       1000 non-null   object \n",
      " 23  Exterior1st    1000 non-null   object \n",
      " 24  Exterior2nd    1000 non-null   object \n",
      " 25  MasVnrType     410 non-null    object \n",
      " 26  MasVnrArea     994 non-null    float64\n",
      " 27  ExterQual      1000 non-null   object \n",
      " 28  ExterCond      1000 non-null   object \n",
      " 29  Foundation     1000 non-null   object \n",
      " 30  BsmtQual       976 non-null    object \n",
      " 31  BsmtCond       976 non-null    object \n",
      " 32  BsmtExposure   975 non-null    object \n",
      " 33  BsmtFinType1   976 non-null    object \n",
      " 34  BsmtFinSF1     1000 non-null   int64  \n",
      " 35  BsmtFinType2   975 non-null    object \n",
      " 36  BsmtFinSF2     1000 non-null   int64  \n",
      " 37  BsmtUnfSF      1000 non-null   int64  \n",
      " 38  TotalBsmtSF    1000 non-null   int64  \n",
      " 39  Heating        1000 non-null   object \n",
      " 40  HeatingQC      1000 non-null   object \n",
      " 41  CentralAir     1000 non-null   object \n",
      " 42  Electrical     1000 non-null   object \n",
      " 43  1stFlrSF       1000 non-null   int64  \n",
      " 44  2ndFlrSF       1000 non-null   int64  \n",
      " 45  LowQualFinSF   1000 non-null   int64  \n",
      " 46  GrLivArea      1000 non-null   int64  \n",
      " 47  BsmtFullBath   1000 non-null   int64  \n",
      " 48  BsmtHalfBath   1000 non-null   int64  \n",
      " 49  FullBath       1000 non-null   int64  \n",
      " 50  HalfBath       1000 non-null   int64  \n",
      " 51  BedroomAbvGr   1000 non-null   int64  \n",
      " 52  KitchenAbvGr   1000 non-null   int64  \n",
      " 53  KitchenQual    1000 non-null   object \n",
      " 54  TotRmsAbvGrd   1000 non-null   int64  \n",
      " 55  Functional     1000 non-null   object \n",
      " 56  Fireplaces     1000 non-null   int64  \n",
      " 57  FireplaceQu    522 non-null    object \n",
      " 58  GarageType     944 non-null    object \n",
      " 59  GarageYrBlt    944 non-null    float64\n",
      " 60  GarageFinish   944 non-null    object \n",
      " 61  GarageCars     1000 non-null   int64  \n",
      " 62  GarageArea     1000 non-null   int64  \n",
      " 63  GarageQual     944 non-null    object \n",
      " 64  GarageCond     944 non-null    object \n",
      " 65  PavedDrive     1000 non-null   object \n",
      " 66  WoodDeckSF     1000 non-null   int64  \n",
      " 67  OpenPorchSF    1000 non-null   int64  \n",
      " 68  EnclosedPorch  1000 non-null   int64  \n",
      " 69  3SsnPorch      1000 non-null   int64  \n",
      " 70  ScreenPorch    1000 non-null   int64  \n",
      " 71  PoolArea       1000 non-null   int64  \n",
      " 72  PoolQC         2 non-null      object \n",
      " 73  Fence          194 non-null    object \n",
      " 74  MiscFeature    43 non-null     object \n",
      " 75  MiscVal        1000 non-null   int64  \n",
      " 76  MoSold         1000 non-null   int64  \n",
      " 77  YrSold         1000 non-null   int64  \n",
      " 78  SaleType       1000 non-null   object \n",
      " 79  SaleCondition  1000 non-null   object \n",
      " 80  SalePrice      1000 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 632.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1. Load the dataset\n",
    "# -----------------------------\n",
    "# Replace 'house_prices.csv' with the path to your dataset.\n",
    "data = pd.read_csv('train.csv')\n",
    "data\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
      "       ...\n",
      "       'SaleType_ConLI', 'SaleType_ConLw', 'SaleType_New', 'SaleType_Oth',\n",
      "       'SaleType_WD', 'SaleCondition_AdjLand', 'SaleCondition_Alloca',\n",
      "       'SaleCondition_Family', 'SaleCondition_Normal',\n",
      "       'SaleCondition_Partial'],\n",
      "      dtype='object', length=229)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 2. Data Cleaning\n",
    "# -----------------------------\n",
    "# Select only numeric columns that have no missing data.\n",
    "# Identify categorical columns (if they are not already of type 'category')\n",
    "# Identify categorical columns (if they are not already type 'category')\n",
    "categorical_cols = data.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# One-hot encode these columns (original columns are dropped automatically)\n",
    "data = pd.get_dummies(data, columns=categorical_cols, dtype=int,drop_first=True)\n",
    "\n",
    "#numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "clean_numeric_cols = [col for col in data if data[col].isna().sum() == 0]\n",
    "data_clean = data[clean_numeric_cols]\n",
    "print(data_clean.columns)\n",
    "\n",
    "# Ensure that the target column 'price' is present.\n",
    "if 'SalePrice' not in data_clean.columns:\n",
    "    raise ValueError(\"The target column 'price' is not present in the complete numeric data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected top 4 features: ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'ExterQual_TA', 'TotRmsAbvGrd', 'FullBath', 'KitchenQual_TA', 'YearBuilt', 'YearRemodAdd', 'Foundation_PConc', 'Fireplaces', 'BsmtQual_TA', 'Neighborhood_NridgHt', 'ExterQual_Gd', 'BsmtFinType1_GLQ', 'GarageFinish_Unf', 'BsmtFinSF1']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 3. Feature Selection\n",
    "# -----------------------------\n",
    "# Compute the correlation matrix using only the cleaned numeric data.\n",
    "corr_matrix = data_clean.corr()\n",
    "\n",
    "# Compute absolute correlations of features with the target and drop the target itself.\n",
    "target_corr = corr_matrix['SalePrice'].drop('SalePrice').abs().sort_values(ascending=False)\n",
    "\n",
    "# Select only the top 4 features with the highest correlation with 'SalesPrice'\n",
    "top4_features = target_corr.head(20).index\n",
    "print(\"Selected top 4 features:\", list(top4_features))\n",
    "\n",
    "# Define input features (X) and target variable (y).\n",
    "X = data_clean[top4_features].values\n",
    "y = data_clean['SalePrice'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4. Data Preprocessing\n",
    "# -----------------------------\n",
    "# Split the data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features to improve training stability.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy arrays to PyTorch tensors.\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create a TensorDataset and DataLoader for batch processing.\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5. Define the Neural Network Model\n",
    "# -----------------------------\n",
    "class HousePriceModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(HousePriceModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)  # Output layer for regression\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HousePriceModel(input_dim=X_train.shape[1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 40836314562.5600\n",
      "Epoch [20/1000], Loss: 38683634237.4400\n",
      "Epoch [30/1000], Loss: 33184947650.5600\n",
      "Epoch [40/1000], Loss: 24853117255.6800\n",
      "Epoch [50/1000], Loss: 16167774003.2000\n",
      "Epoch [60/1000], Loss: 9991072849.9200\n",
      "Epoch [70/1000], Loss: 7118325504.0000\n",
      "Epoch [80/1000], Loss: 6117254563.8400\n",
      "Epoch [90/1000], Loss: 5634376878.0800\n",
      "Epoch [100/1000], Loss: 5253980723.2000\n",
      "Epoch [110/1000], Loss: 4895113697.2800\n",
      "Epoch [120/1000], Loss: 4558248929.2800\n",
      "Epoch [130/1000], Loss: 4246249041.9200\n",
      "Epoch [140/1000], Loss: 3958298127.3600\n",
      "Epoch [150/1000], Loss: 3692963031.0400\n",
      "Epoch [160/1000], Loss: 3456343992.3200\n",
      "Epoch [170/1000], Loss: 3244037294.0800\n",
      "Epoch [180/1000], Loss: 3059558328.3200\n",
      "Epoch [190/1000], Loss: 2902188282.8800\n",
      "Epoch [200/1000], Loss: 2766522869.7600\n",
      "Epoch [210/1000], Loss: 2651581352.9600\n",
      "Epoch [220/1000], Loss: 2550278983.6800\n",
      "Epoch [230/1000], Loss: 2462819069.4400\n",
      "Epoch [240/1000], Loss: 2382769735.6800\n",
      "Epoch [250/1000], Loss: 2308772060.1600\n",
      "Epoch [260/1000], Loss: 2239738521.6000\n",
      "Epoch [270/1000], Loss: 2174612249.6000\n",
      "Epoch [280/1000], Loss: 2112285263.3600\n",
      "Epoch [290/1000], Loss: 2053910556.1600\n",
      "Epoch [300/1000], Loss: 1998184148.4800\n",
      "Epoch [310/1000], Loss: 1945309025.2800\n",
      "Epoch [320/1000], Loss: 1896256903.6800\n",
      "Epoch [330/1000], Loss: 1848312202.2400\n",
      "Epoch [340/1000], Loss: 1805206932.4800\n",
      "Epoch [350/1000], Loss: 1763408240.6400\n",
      "Epoch [360/1000], Loss: 1719825285.1200\n",
      "Epoch [370/1000], Loss: 1680614653.4400\n",
      "Epoch [380/1000], Loss: 1642433195.5200\n",
      "Epoch [390/1000], Loss: 1606553459.2000\n",
      "Epoch [400/1000], Loss: 1571356564.4800\n",
      "Epoch [410/1000], Loss: 1538135029.7600\n",
      "Epoch [420/1000], Loss: 1506008271.3600\n",
      "Epoch [430/1000], Loss: 1475110696.9600\n",
      "Epoch [440/1000], Loss: 1447126407.6800\n",
      "Epoch [450/1000], Loss: 1420237859.8400\n",
      "Epoch [460/1000], Loss: 1393100823.0400\n",
      "Epoch [470/1000], Loss: 1368542026.2400\n",
      "Epoch [480/1000], Loss: 1347413320.9600\n",
      "Epoch [490/1000], Loss: 1325261600.0000\n",
      "Epoch [500/1000], Loss: 1305751599.3600\n",
      "Epoch [510/1000], Loss: 1291163740.1600\n",
      "Epoch [520/1000], Loss: 1270940099.8400\n",
      "Epoch [530/1000], Loss: 1254112048.6400\n",
      "Epoch [540/1000], Loss: 1239706140.1600\n",
      "Epoch [550/1000], Loss: 1227540716.8000\n",
      "Epoch [560/1000], Loss: 1211866042.8800\n",
      "Epoch [570/1000], Loss: 1198418078.7200\n",
      "Epoch [580/1000], Loss: 1185581568.0000\n",
      "Epoch [590/1000], Loss: 1173488230.4000\n",
      "Epoch [600/1000], Loss: 1163421793.2800\n",
      "Epoch [610/1000], Loss: 1150651729.9200\n",
      "Epoch [620/1000], Loss: 1139841580.8000\n",
      "Epoch [630/1000], Loss: 1128798812.1600\n",
      "Epoch [640/1000], Loss: 1118751829.7600\n",
      "Epoch [650/1000], Loss: 1109634053.1200\n",
      "Epoch [660/1000], Loss: 1099414421.7600\n",
      "Epoch [670/1000], Loss: 1090205952.0000\n",
      "Epoch [680/1000], Loss: 1081151813.1200\n",
      "Epoch [690/1000], Loss: 1071333356.8000\n",
      "Epoch [700/1000], Loss: 1063155228.1600\n",
      "Epoch [710/1000], Loss: 1055606087.6800\n",
      "Epoch [720/1000], Loss: 1048066956.8000\n",
      "Epoch [730/1000], Loss: 1040483765.1200\n",
      "Epoch [740/1000], Loss: 1034683051.5200\n",
      "Epoch [750/1000], Loss: 1027846805.7600\n",
      "Epoch [760/1000], Loss: 1021034699.5200\n",
      "Epoch [770/1000], Loss: 1017800568.3200\n",
      "Epoch [780/1000], Loss: 1010426499.8400\n",
      "Epoch [790/1000], Loss: 1003587444.4800\n",
      "Epoch [800/1000], Loss: 998414208.0000\n",
      "Epoch [810/1000], Loss: 994008536.3200\n",
      "Epoch [820/1000], Loss: 989702368.0000\n",
      "Epoch [830/1000], Loss: 984044340.4800\n",
      "Epoch [840/1000], Loss: 980345850.8800\n",
      "Epoch [850/1000], Loss: 975671224.9600\n",
      "Epoch [860/1000], Loss: 973496683.5200\n",
      "Epoch [870/1000], Loss: 969490736.6400\n",
      "Epoch [880/1000], Loss: 965850593.2800\n",
      "Epoch [890/1000], Loss: 961814972.1600\n",
      "Epoch [900/1000], Loss: 958088296.9600\n",
      "Epoch [910/1000], Loss: 955686682.8800\n",
      "Epoch [920/1000], Loss: 952613734.4000\n",
      "Epoch [930/1000], Loss: 951894910.7200\n",
      "Epoch [940/1000], Loss: 946547118.0800\n",
      "Epoch [950/1000], Loss: 943475921.9200\n",
      "Epoch [960/1000], Loss: 941158076.1600\n",
      "Epoch [970/1000], Loss: 938916184.3200\n",
      "Epoch [980/1000], Loss: 937710378.2400\n",
      "Epoch [990/1000], Loss: 934779914.2400\n",
      "Epoch [1000/1000], Loss: 932658671.3600\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6. Set Up Loss Function and Optimizer\n",
    "# -----------------------------\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Train the Model\n",
    "# -----------------------------\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Squared Error: 720409856.0\n",
      "Test MSE (scikit-learn): 720409856.0\n"
     ]
    }
   ],
   "source": [
    "# 8. Evaluate the Model\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor.to(device))\n",
    "    test_loss = criterion(predictions, y_test_tensor.to(device)).item()\n",
    "    print(\"Test Mean Squared Error:\", test_loss)\n",
    "\n",
    "# Optionally, to evaluate using scikit-learn's MSE:\n",
    "predictions_np = predictions.cpu().numpy()\n",
    "mse = mean_squared_error(y_test, predictions_np)\n",
    "print(\"Test MSE (scikit-learn):\", mse)\n",
    "#Test Mean Squared Error: 935741376.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
